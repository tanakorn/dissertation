\section{Distributed Concurrency Bugs}

Distributed concurrency bugs (DC bugs) are bugs that caused by nondeterministic
orders of distributed events. Distributed events could be message arrivals,
hardware crashes/reboots, network timeout, \etc\ Cloud systems execute multiple
complicated distributed protocols concurrently (\eg, serving users' requests,
operating background tasks, and combined with untimely hardware failures), and
possible interleavings of the distributed events are beyond developers'
anticipation, which some interleavings might not be handled properly, and can
cause catastrophic failures such as data loss/inconsistency and downtimes.
Compared to the ``countless'' of efforts in combating ``local'' concurrency bugs
in multi-threaded software, DC bugs have not received the same amount of
attention within the research community.

Here is our contributions to combat DC bugs in systematic and comprehensive manners,

\begin{enumerate}

\item Semantic-Aware Model Checking (SAMC): we advance the state of the art of
model checking for distributed systems by adopting white-box approach to tackle
state-space explosion, the current limitation of model checking.

\item Taxonomy for DC bugs (\taxdc): we perform an in-depth study of more than
100 real-world DC bugs and built a first complet taxonomy for DC bugs. This
study will give insight to guide many future research work on DC bugs.

\end{enumerate}

The brief detail of these two works are discussed below.

\subsection{Semantic-Aware Model Checking}

One powerful method for discovering hidden DC bugs is the use of an
\textit{implementation-level distributed system model checker} (\textbf{dmck}).
A dmck can discover buggy interleavings that lead to DC bugs by reordering every
possibility of nondeterministic distributed events. The last ten years have seen
a rise of dmcks such as MaceMC, \modist, or Demeter. One big challenge faced by a
dmck is the state-space explosion problem (\ie, there are too many distributed
events to re-order). To address this, existing dmcks adopt a random walk or
basic reduction techniques such as dynamic partial order reduction (DPOR).
Despite these early successes, existing approaches cannot unearth many
real-world DC bugs, so we advance state of the art of dmck to combat DC bugs.

We start by addressing two limitations of existing dmcks. First, existing dmcks
treat every target system as a complete \textit{black box}, and perform
unnecessary reorderings of distributed events that would lead to the same states
(\ie, redundant executions). Second, they do not incorporate complex multiple
fault events (\eg, crashes, reboots, \etc) into their exploration strategies, as
such inclusion would exacerbate the state-space explosion problem.

To address these limitations, we introduce Semantic-Aware Model Checking
(\textbf{SAMC}), a novel white-box model checking approach that takes
\textit{semantic knowledge} of how distributed events (specifically, messages,
crashes, and reboots) are processed by the target system and incorporates that
to create reduction policies. The policies are based on sound reduction
techniques such as DPOR and symmetry. The policies tell SAMC not to re-order
some pairs of events such as message-message pairs, and message-crash pairs, yet
preserves soundness, because those cut out re-orderings are redundant, and
unnecessary to check.

SAMC can reproduce twelve old bugs in three cloud distributed systems
(Cassandra, Hadoop MapReduce, and ZooKeeper) involving 30-120 distributed events
and multiple crashes and reboots. Some of these bugs cannot be unearthed by
non-SAMC approaches, even after two days. SAMC can find the bugs up to 340 (49x
on average) faster compared to state-of-the-art techniques, it found two new
bugs in Hadoop MapReduce and ZooKeeper.

\subsection{DC Bug Study \& Taxonomy}

Bug and failure studies can significantly guide many aspects of dependability
research. Many researchers have recently employed formal studies on bugs and
failures \cite{Jin+12-PerformanceBugs, Li+13-ScopeBugStudy, Li+07-MemoryErrors,
Lu+08-ConcurrencyBugStudy, Sahoo+10-StudyBugsServerSoftware,
SridharanLiberty12-StudyDRAMFailures, Xiao+14-NonDetMR,
Yin+11-StudyConfErrors}.
%
However, we are not aware of any public large-scale DC-bug study, a recent study
from Microsoft analyzed the effect of distributed concurrency of workload and
only studied five DC bugs in MapReduce \cite{Xiao+14-NonDetMR}, and researchers
from NEC Labs dissected only network-failure-related DC bugs to study and did
not publicly release it \cite{Joshi+13-SetsudoTesting}.

In this dissertation, we fill the void by performing large-scale DC-bug study.
We study 104 real-world DC bugs from four various popular cloud-scale
distributed systems: Cassandra, HBase, Hadoop MapReduce/Yarn, and ZooKeeper. We
study DC bugs in all aspects including trigger, errors and failures, and fixes. 

For triggering conditions, we study DC bugs from two perspectives:
\begin{enumerate}

\item Timing conditions: For every DC bug, we identify the smallest set of
concurrent events E, so that a specific ordering of E can guarantee the bug
manifestation. This is similar to the interleaving condition for local
concurrency bugs.

\item Input preconditions: In order for those events in E to happen, regardless
of the ordering, certain inputs or fault conditions (\eg, node crashes) must
occur. This is similar to the input condition for local concurrency bugs.

\end{enumerate}
Understanding the triggering can help the design of testing tools that can
proactively trigger DC bugs, bug detection tools that can predict which bugs can
be triggered through program analysis, and failure prevention tools that can
sabotage the triggering conditions at run time.

Other than the trigger, we also look into errors and failures. From the
triggering conditions, we then scrutinize the first error that happens
immediately after. First errors are the pivotal point that bridges the
triggering and error-propagation process. We categorize first errors into {\em
local} errors and {\em global} errors, based on whether they can be observed
from the triggering node alone. 
%
And after the first errors, we track down to system failures that are noticeable
to users such as downtimes, lost/corrupted/inconsistent data, failed operations,
and degraded performance. Identifying errors and failures help failure diagnosis
get closer to disclosing bug triggering and root causes and help bug detection
get closer to accurately predict failures.

Lastly, we study how developers fix DC bugs to understand their fix strategies.
We want to see how different DC bug fixes compared to local concurrency bugs. In
general, we find that DC bugs can be fixed by either disabling the triggering
timing or changing the system's handling to that timing ({\em fix timing} vs.
{\em fix handling}). The former prevents concurrency with extra synchronization
and the latter allows concurrency by handling untimely events properly.
Understanding the fix strategies will help research on runtime failure
prevention and automatic bug fixing.

Our contribution from the study is the first complete taxonomy of DC bugs which
named \taxdc. \taxdc\ contains in-depth characteristics of DC bugs, stored in
the form of 2,083 classification labels and 4,528 lines of re-enumerated steps
to the bugs that we manually added. And as mentioned above, \taxdc\ can guide
various future research on combating DC bugs such as model checking, bug
detections, failure diagnosis, and failure prevention and fixing.

