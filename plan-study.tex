\section{Bug Study}

Bug or failure studies can significantly guide many aspects of dependability
research. Many dependability researchers have recently employed formal studies
on bugs and failures such as the studies on large-scale system bugs/failures
from Microsoft \cite{Guo+13-CureIsWorse, Li+13-ScopeBugStudy} These studies can
identify opportunities for new research, build taxonomies of new problems, or
test new tools. I started my research by doing formal bug study to gain
foundations of combating DC bugs.

\subsection{Cloud Bug Study}

As an initiative, our group have performed the largest bugs study in six 
important Apache cloud infrastructures including Cassandra, Flume, Hadoop
MapReduce, HBase, HDFS, and ZooKeeper \cite{Gunawi+14-Cbs}. We reviewed in
total 21,399 submitted issues within a three-year period (2011-2014) in Apache
bug repositories. We perform a deep analysis of 3,655 ``vital'' issues (\ie,
real issues affecting deployments) with a set of detailed classifications. This
work led us to several interesting dependability research questions, and was 
the main source of my DC-bug taxonomy work.

\subsection{DC Bug Taxonomy} 

While there have been many LC-bug studies, I am not aware of any large-scale
study of DC bugs. A recent study from Microsoft analyzed the effect of
distributed concurrency on workload and only studied five DC bugs in MapReduce
systems \footnote{Tian Xiao, Jiaxing Zhang, Hucheng Zhou, Zhenyu Guo, Sean
McDirmid, Wei Lin, Wenguang Chen, and Lidong Zhou. Nondeterminism in MapReduce
Considered Harmful?  An Empirical Study on Non-commutative Aggregators in
MapReduce Programs. ICSE '14}. To fill the void, I as one of the project
leaders, have created the largest and most comprehensive taxonomy of 104
real-world DC bugs (named \taxdc) from Cassandra, HBase, Hadoop MapReduce/Yarn,
and ZooKeeper \cite{Leesatapornwongsa+16-TaxDc}. \taxdc\ contains in-depth
characteristics of DC bugs, stored in the form of 2,083 classification labels
and 4,528 lines of re-enumerated steps to the bugs that I manually added.
Motivated by the availability of bug benchmarks for LC bugs, I will release
\taxdc\ as a large-scale DC bugs benchmark.

With \taxdc\, I can answer important questions such as: How often are DC bugs
reported from real deployments? What types of DC bugs exist in real world?
What are the root causes of DC bugs (out-of-order messages, failures, \etc)?
Are existing LC-bug-detection tools applicable for DC bugs? How do developers
fix DC bugs (by adding locks, states, \etc)? What are the inputs/triggering
conditions?  What are the minimum number of distributed events needed to
trigger the bugs (how many messages to re-order, failures to inject, \etc)?
What errors/effects (specification violations) are caused by DC bugs (deadlock,
data loss, state inconsistency, performance problems, \etc)? How do propagation
chains form from the root causes to errors? The answers to these questions will
guide my subsequent research projects.

\section{Distributed System Model Checking}

One powerful method for discovering hidden DC bugs is the use of an
\textit{implementation-level distributed system model checker} (\textbf{dmck}).
By re-ordering non-deterministic distributed events, a dmck can discover buggy
interleavings that lead to DC bugs. The last eight years have seen a rise of
dmcks such as MaceMC \footnote{Charles Killian, James Anderson, Ranjit Jhala,
and Amin Vahdat. Life, Death, and the Critical Transition: Finding Liveness Bugs
in Systems Code. NSDI '07}, \modist\ \cite{Yang+09-Modist}, or Demeter 
\cite{Guo+11-Demeter}. One big challenge faced by a dmck is the
state-space explosion problem (\ie, there are too many distributed events to
re-order). To address this, existing dmcks adopt a random walk or basic
reduction techniques such as dynamic partial order reduction (DPOR). Despite
these early successes, existing approaches cannot unearth many real-world DC
bugs, so I am advancing the state of the art of dmck to combat DC bugs, which I
describe below.

\subsection{Semantic-Aware Model Checking (Initial Work)}

I started my work by specifically addressing two limitations of existing dmcks.
First, existing dmcks treat every target system as a complete \textit{black
box}, and therefore perform unnecessary reorderings of distributed events that
would lead to the same explored states (\ie, redundant executions). Second,
they do not incorporate complex multiple fault events (\eg, crashes, reboots)
into their exploration strategies, as such inclusion would exacerbate the
state-space explosion problem.

To address these limitations, I built Semantic-Aware Model Checking
(\textbf{SAMC}) \cite{Leesatapornwongsa+15-SamcIssta,Leesatapornwongsa+14-Samc},
a novel white-box model checking approach that takes \textit{semantic knowledge}
of how distributed events (specifically, messages, crashes, and reboots) are
processed by the target system and incorporates that information in reduction
policies.  The policies are based on sound reduction techniques such as DPOR and
symmetry.  The policies tell SAMC not to re-order some pairs of events such as
message-message pairs or crash-message pairs, yet preserves soundness, because
those cut out re-orderings are redundant.

I built SAMC from scratch with 10 KLOC and I was able to reproduce 12 old bugs
in 3 cloud systems involving 30-120 distributed events and multiple crashes and
reboots. Some of these bugs cannot be unearthed by non-SAMC approaches, even
after two days. SAMC can find the bugs up to 271x (33x on average) faster
compared to state-of-the-art techniques. Additionally, I found two new bugs in
Hadoop MapReduce and ZooKeeper.


