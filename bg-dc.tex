\section{Distributed Concurrency}
\label{bg-dc}

\subsection{Local Concurrency and Distributed Concurrency}

\input{fig-zk1264}

A well-known concurrency that developers most familiar with is from thread
execution interleaving in multi-threaded software or what we call in this
dissertation ``\textit{local concurrency}''. Multi-threaded software has become
common in the age of multi-core processor, however, building multi-threaded
software is hard. Developers need to handle all possible interleaving of
multiple threads that are accessing to same data properly, otherwise
concurrency bugs will happen. These bugs are timing-related and
non-deterministic, and they are extremely difficult to test and debug.

For distributed systems, other than local concurrency, the systems are also
subject to ``\textit{distributed concurrency}'' that is caused from
interleaving of computations in multiple nodes. Nodes in distributed systems do
not have shared memory and they access data in other nodes via network
communication, so concurrency in distributed systems can also come from
concurrent message arrivals and internal computations in running nodes.

Other than timing of message arrivals and local computations, concurrent bugs
in distributed systems are caused from timing of failures as well. Cloud
systems are built on top of commodity hardware for horizontal scaling purpose
(Section \ref{bg-sc-type}). This commodity hardware is unreliable, and hardware
failures are not an option \cite{Abadi09-Cloud, Gunawi+11-FaaS-TR,
Hamilton07-Deploying}. Cloud distributed systems need to response to these
failures, they need to detect and recover from the failures and makes sure that
users' data will not be lost or corrupted. Guaranteeing this correctness is
proven to be hard \cite{Do+14-Phd, Gunawi+11-FateDestini}, cloud-scale
distributed systems need to handle failures that can happen at any time and at
any state of the systems. Some ordering of message arrivals could make systems
into state that developers never anticipate and is prone to error when failure
happens.

Considering hardware failures, concurrency bugs in cloud distributed systems
is not only about interleaving of message arrivals and local computations, but
also timing of hardware failures as well. Figure \ref{fig-zk1264} shows an
example of a concurrency bug that happens because of untimely ordering of
message arrivals and node crashes. This bugs surfaces only if a follower
receives an UPTODATE message (step 14) after a commit message (step 12), and the
follower crashes before it does snapshot (step 20); only untimely message
arrivals or the timing of follower crash is not enough for bug to surface.

\subsection{Distributed Systems Model Checker (DMCK)}
\label{sec-bg-dmck}

In order to unearth DC bugs the question we have to answer is: ``{\em can we
exercise necessary conditions (\ie workloads and faults) and test different
event re-ordering to hit the bugs?}''. This is the job of distributed system
model checkers (dmck), which are gaining popularity recently
\cite{Guo+11-Demeter, Killian+07-LifeDeathMaceMC, Simsa+10-Dbug,
Yang+09-Modist}. Dmck works by intercepting distributed events and permuting
their ordering, and hereby pushing the target system into corner-case situations
and unearthing hard-to-find bugs. However, the more events included, the more
scalability issues will arise due to state-space explosion.

\input{fig-dmck}
The last ten years have seen a rise of software model checker that checks
distributed systems directly at the implementation level.  Figure~\ref{fig-dmck}
illustrates a dmck integration to a target distributed system, a simple
representation of existing dmck frameworks~\cite{Guo+11-Demeter,
Killian+07-LifeDeathMaceMC, Simsa+10-Dbug, Yang+09-Modist}.  The dmck inserts an
interposition layer in each node of the target system with the purpose of
controlling all important events (\eg, network messages, timeouts) and
preventing the target system to process the events until the dmck enables them.
A main dmck mechanism is the permutation of events; the goal is to push the
target system into all possible ordering scenarios.  For example, the dmck can
enforce \ts{abcd} ordering in one execution, \ts{bcad} in another, and so on.

\subsection{Symbolic Execution}
% symbolic execution ...
Symbolic execution is another powerful formal method to verify systems
correctness.  Symbolic execution also faces an explosion problem, specifically
the path explosion problem.  A huge body of work has successfully addressed the
problem and made symbolic execution scale to large (non-distributed) software
systems \cite{Bucur+11-ParallelSymEx, Cadar+08-KLEE, Chipounov+11-S2e,
Cui+13-RuleDirectedSymExec, Zamfir+10-Synthesis}.  Symbolic execution and model
checking can formally be combined into a more powerful
method \cite{Burch+92-SymbolicMC}, however this concept has not permeated the
world of distributed systems; it is challenging to track symbolic values across
distributed nodes.

\subsection{Fault Injector}
% fault injector
Reliability bugs are often caused by incorrect handling of
failures \cite{Gunawi+11-FateDestini, Gunawi+08-EIO}.  Fault-injection testing
however is challenging due to the large number of possible failures to inject.
This challenge led to the development of efficient fault-injection testing
frameworks.  For example, AFEX \cite{Banabic+12-Blackbox} and
LFI \cite{Marinescu+10-ExtensibleLFI} automatically prioritize ``high-impact
targets'' (\eg, unchecked system calls).  These novel frameworks target
non-distributed systems and thus the techniques are different than ours.

% distributed systems
Similarly, recent work highlights the importance of testing faults in cloud
systems (\eg, \fate\ \cite{Gunawi+11-FateDestini}, \setsudo\
\cite{Joshi+13-SetsudoTesting}, \prefail\ \cite{Joshi+11-PreFail}, and OpenStack
fault-injector \cite{Ju+13-FaultResOpenStack}). However, these frameworks are
not a dmck; they cannot re-order concurrent messages and failures and therefore
cannot catch distributed concurrency bugs systematically.

