

\section{Evaluation}
\label{sec-sck-eval}


We now evaluate our \sck integration to Cassandra, Riak,
and Voldemort.  Our evaluation answers the following questions.
%
\sec\ref{eval-colo}: What is the maximum colocation factor achieved?
%
\sec\ref{eval-accu}: How accurate is \sck compared to real deployments?
%
\sec\ref{eval-bugs}: Can \sck find old scalability bugs?
%
\sec\ref{eval-new}: Can \sck reveal new bugs?
%
% \sec\ref{eval-mem}: How long is the output and time memoization overhead?
%
\sec\ref{eval-other}: Does our evaluation compare well with other work?


We use the Nome cluster; each machine has 16-core AMD Opteron(tm) 8454
processors with 32-GB DRAM \cite{NomeNodes}.
% link to Nome spec on website, ask Korn
%
To measure \sck accuracy (\sec\ref{eval-accu}), we compare it with real
deployments of 32, 64, 128, 256, and 512 nodes, deployed on at most 128 Nome
machines.  
%
\footnote{Our target protocols only make at most 2 busy cores per
node, which justifies why we run 8 nodes per one 16-core machine for the real
deployment. }
%

\input{sck-evalcolo}
\input{sck-accu}
\input{sck-oldbug}
\input{sck-newbug}
%\input{sck-compare}

